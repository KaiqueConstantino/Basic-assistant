{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfJJz8Q1M0+QWqCgVQcDzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaiqueConstantino/Basic-assistant/blob/main/Virtual_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic Virtual Assitant Project\n"
      ],
      "metadata": {
        "id": "WByo2nBfR4M0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE2tQxmSRk2h"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas\n",
        "import speech_recognition as sr  # Para reconhecimento de fala\n",
        "import pyttsx3  # Para conversão de texto em áudio\n",
        "import webbrowser  # Para abrir URLs no navegador"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 1: Configuração do Motor de Texto para Fala (TTS)\n",
        "Adicionamos a configuração inicial para que a assistente virtual fale as respostas."
      ],
      "metadata": {
        "id": "Q6MMFl8nSUpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do motor de texto para fala (TTS)\n",
        "# pyttsx3 é usado para sintetizar áudio a partir de texto\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# Função para transformar texto em fala\n",
        "def speak(text):\n",
        "    \"\"\"\n",
        "    Converte o texto fornecido em áudio falado.\n",
        "    \"\"\"\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()"
      ],
      "metadata": {
        "id": "ZZ7NkbCtUS6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 2: Reconhecimento de Fala (Speech to Text)\n",
        "\n",
        "Aqui configuramos o reconhecimento de áudio usando a biblioteca SpeechRecognition."
      ],
      "metadata": {
        "id": "RqqkG7lvSfl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para capturar e reconhecer áudio do microfone\n",
        "def recognize_speech():\n",
        "    \"\"\"\n",
        "    Escuta o microfone e converte o áudio em texto.\n",
        "    retorna: Texto reconhecido ou mensagem de erro.\n",
        "    \"\"\"\n",
        "    recognizer = sr.Recognizer()  # Inicializa o reconhecedor de fala\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Diga algo...\")\n",
        "        try:\n",
        "            # Escutando o áudio do microfone\n",
        "            audio = recognizer.listen(source)\n",
        "\n",
        "            # Reconhecendo o texto usando o Google Speech Recognition\n",
        "            text = recognizer.recognize_google(audio, language=\"pt-BR\")\n",
        "            return text.lower()\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Não entendi o que você disse.\"\n",
        "        except sr.RequestError:\n",
        "            return \"Erro ao acessar o serviço de reconhecimento de fala.\""
      ],
      "metadata": {
        "id": "FoMa8LaOSkvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3: Automação com Base no Comando\n",
        "\n",
        "Aqui você define as ações que a assistente deve realizar com base nos comandos reconhecidos."
      ],
      "metadata": {
        "id": "gppMC3JjS12W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para executar comandos\n",
        "def execute_command(command):\n",
        "    \"\"\"\n",
        "    Executa ações com base no comando reconhecido.\n",
        "    :param command: Texto do comando reconhecido.\n",
        "    \"\"\"\n",
        "    if \"youtube\" in command:\n",
        "        speak(\"Abrindo YouTube\")\n",
        "        webbrowser.open(\"https://www.youtube.com\")\n",
        "    elif \"google\" in command:\n",
        "        speak(\"Abrindo Google\")\n",
        "        webbrowser.open(\"https://www.google.com\")\n",
        "    else:\n",
        "        speak(\"Comando não reconhecido.\")"
      ],
      "metadata": {
        "id": "2QHp5opdSxsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 4: Loop Principal da Assistente\n",
        "Nesta parte, combinamos as funções anteriores em um loop que executa continuamente até que seja interrompido."
      ],
      "metadata": {
        "id": "lTkBhUwcS4ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop principal\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        # Reconhece o comando de voz\n",
        "        command = recognize_speech()\n",
        "\n",
        "        # Mostra o comando reconhecido no console\n",
        "        print(f\"Você disse: {command}\")\n",
        "\n",
        "        # Executa a ação correspondente ao comando\n",
        "        execute_command(command)"
      ],
      "metadata": {
        "id": "2KstWcloS_Tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}